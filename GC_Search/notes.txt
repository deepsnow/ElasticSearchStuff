
May 13, 2015
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Using this query

GET /gc-index/talk/_search
{
  "fields" : ["title", "author", "confid", "url"],
  "query" : {
    "match" : {
      "content" : "peace"
    }
  },
    "highlight" : {
      "fields" : {
        "content" : {"number_of_fragments": 50}
      }
    }
}

in sense (http://localhost:9200/_plugin/marvel/sense/index.html), I've learned that I really need to index only the text of the GC conf talks and not any of the HTML.

When all of the first 50 hits on "peace" from Elder's Perry's talk "FINDING LASTING PEACE AND BUILDING ETERNAL FAMILIES" come from markup, then that means there is way too much markup...

I need to download the PDFs and strip the text out of them, but how will I do that?

And, I need to figure out how to stop ES from returning the entire talk when it has hits. I just want the highlights...

July 7, 2015
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

how to delete in Sense? "DELETE gc-index"

I can build an index like this in Sense:

PUT gc-index
{
  "settings" : {
    "analysis" : {
      "analyzer" : {
        "remove_html" : {
          "tokenizer" : "standard",
          "char_filter" : [ "html_strip" ]
          }
        }
      }
    }
  
,
  
    "mappings" : {
      "talk" : {
        "properties" : {
          "title" : { "type": "string" },
          "author" : { "type": "string" },
          "confid" : { "type": "string" },
          "content" : { "type": "string", "analyzer": "remove_html" }
        }
      }
    }
  
}  

And, I can do it in code as well. See ESIndexOps.py and experimental_index_create.py.

Here's a way to test index settings: GET /gc-index/_settings,_mappings

I've succeeded in creating the index via python with the desired analyzer (with HTML char removal), and now I only 13 hits when I search for peace (as opposed to the 50 that I used to get according to the above?), but the hits still return the entire content of each talk as well as the individual hits in the highlights section.

How did it look before? I need to do a before and after test to see if my html removal made a positive difference...


July 9, 2015
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

I've discovered that my attempt toe create an index that uses the "html_strip" character filter analyzer does indeed work properly. (I compared a gc_index with the analyzer to a gc_index-2 without it and found that gc_index behaved as desired (returning only content hits and not markup hits).) That's great!!!

Now, where are the other conference talks published? I've asked Ronald to tell me where they can be found.

July 10, 2015
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

I'm still trying to load all of the GC talks that are available on lds.org (back to 1971). I can parse the archive page successfully, and I can load all of the talks from Apr 2015 and Oct 2014, but I error out on Apr 2014. Why? The second talk of that Conference has a title string with no author listed. It seems that I'm going to have to do a more complex parse if I want to get the title and author reliably.

Also, there are unicode characters in the <title> string that I am likely not handling properly at this point. They look badly when I output them to a text file... Will this happen when I get title and auther further down in the page?

OK, looking back at the output file, it appears that once Notepad++ refreshed the unicode chars were gone...? I can't see them any more...

Now that I'm handling the unicode chars as such, I can't display debugging output on the command line anymore because some of the chars won't render. Or, can I tell print the encoding?

Going to start on UI in special index containing only two Confs' worth of talks (Apr 2015 and Oct 2014). These can be found in ES index 'gc-index_2confs'.


July 13, 2015
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

What can I do to begin to build my UI?

What would need to change in the Python code to add a URL to my talk mapping?

How can I get ES to refraining from returning the entire talk content?
	Yes!!! The fields option to the search API. See http://stackoverflow.com/questions/9605292/make-elasticsearch-only-return-certain-fields.

Aug 10, 2015
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Where can I get GC content from before 1971?

http://www.reddit.com/r/latterdaysaints/comments/2etwco/why_does_the_general_conference_archive_on_ldsorg/
	https://archive.org/search.php?query=%28collection%3Aconferencereport+OR+mediatype%3Aconferencereport%29+AND+-mediatype%3Acollection&sort=date&page=1
	https://archive.org/details/conferencereport?&sort=date // I like this one!
	http://www.journalofdiscourses.com/
	http://josephsmithpapers.org/the-papers
	http://gospelink.com/browse/category/8 // I don't like this because it's subscription based...
	http://tech.lds.org/forum/viewtopic.php?t=7878-pre-1942-conference-reports
	https://www.lds.org/church/news/church-publishing-40-years-of-conference-audio-and-video?lang=eng
	

Aug 11, 2015
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Tonight I've updated my python GC content retrieving code to also capture each talk's URL. This will be essential to my web app's ability to help users see the full text pertaining to any/all of their search hits.

Here's the Sense URL: http://localhost:9200/_plugin/marvel/sense/index.html

GET /gc/talk/_search
{
  "fields" : ["title", "author", "confid", "url"],
  "query" : {
    "match" : {
      "content" : "peace"
    }
  },
    "highlight" : {
      "fields" : {
        "content" : {"number_of_fragments": 50}
      }
    }
}

Aug 12, 2015
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Pres Eyring's talk title is surrounded in unicode quotes '\u201c', and I can't output this to my cmd.exe. So, I'm trying power shell...

I've tried briefly to figure out how to get the console to display UTF-8, but I got nowhere and so I'm going to redirect console output to a file.

I need to make sure that index creation, with the HTML char stripping, is run every time...

I've found that ES's official JavaScript client is elasiticsearch.js (with the Angular-specific build being elasticsearch.angular.js), and that there are at least two other builds worth considering:
	elastic.js // from fullscale.code, building upon the above
	ElasticUI // Angular directives, building upon elastic.js, see author on http://stackoverflow.com/questions/22661996/example-of-angular-and-elasticsearch
	
elasticsearch.js et all seem to need Bower, which seems to need node.js
	
	https://www.elastic.co/guide/en/elasticsearch/client/javascript-api/current/browser-builds.html
	https://github.com/spalger/elasticsearch-angular-example
	https://www.elastic.co/blog/client-for-node-js-and-the-browser
	
OK, I think I've got my html and js files successfully loading elasticsearch.angular.js!!!

I'm trying to get one search (one round trip to ES and back) to work. Here are some observations arising from that effort:
	1- ES won't find "rehears" in index 'gc' even though Neil L Anderson's talk "Thy Kingdom Come" contains the word "rehearsing".
		ES must tokenize on whole words. How will I do "rehears*" from AngularJS?
	2- How can I determine whether or not I'm actually querying ES from my JS code?
		There are no errors reported in Chrome's JS console...
		Can I inspect this with Fiddler?
		

Aug 14, 2015
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

scraps:
	$scope, client, esFactory
	
OK, I finally got my HTML to call my JS function to call to ES. But, that failed with error:

XMLHttpRequest cannot load file://localhost:9200/gc/talk/_search. Cross origin requests are only supported for protocol schemes: http, data, chrome, chrome-extension, https, chrome-extension-resource.

So, if I access the html with the file:// protocol, then I can't call to HTTP by default because of the "cross origin restriction".
But, this restriction can be worked around by tips in ng-book's section called "Cross-Origin and Same-Origin policy".


Aug 18, 2015
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

OK, I've spent almost all day learning how to use Node.js to act as an HTTP server (http://nodeschool.io/#workshopper-list), and I've had some success. But, I'm still calling ES from the JS executing in the browser (rather than the JS executing within Node.js),
and so now I'm getting this error:

XMLHttpRequest cannot load http://localhost:9200/gc/talk/_search. The 'Access-Control-Allow-Origin' header contains the invalid value 'true'. Origin 'http://localhost' is therefore not allowed access.

I'm going to commit my work to this point. Done!

(I also committed some JS files I generated while going through some NodeSchool tutorials which I found to be very helpful...)

I'm going to spend a few more minutes trying to allow cross-origin operations, if possible. If not, then I'll need to change my es_portal.js to be a REST/JSON API and it will have to talk to ES for me.

OK, after adding the following lines to my elasticsearch.yml file

http.cors.enabled: true
http.cors.allow-origin: "*"

I've been able to round trip from browser (Chrome) to Node.js to ElasticSearch and back again. Now, let's see if I can get the results to display in the HTML...


Aug 24, 2015
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

I've made some very good progress today:
	I can show all of the search hits from each conf talk that contains them.
	I can show each hit in italics because I'm using $sce.trustAsHtml().
	I can show each talk with hits in its own row in a results table, along with a URL to the original online source for the talk.
	
What improvements could I make?
	1- Show only <em> tags, but not other tags, in the HTML from ES that's rendered safe.
	2- 
	3- Don't show an empty table before there are hits.
	4- Show something appropriate when a search is performed but no hits are found.
	5- Sort the results in chronological order?
	6- How to allow stemming, or whatever it will take, in order for "rehears*" to find "rehearsing"...?
	7- Why am I restricted to only 10 hits? I know that "peace" has 27 hits...
	
Which of these should I work on now?

Sorting in chronological order is tricky.
	I've inserted the talks in reverse chronological order (according to output captured during insertion).
		How to reverse that ordering on search hits?
			_id is a string: http://grokbase.com/t/gg/elasticsearch/151vqsb0vf/how-does-sorting-on-id-work, and _uid is as well https://github.com/elastic/elasticsearch/issues/1756
			The latter URL suggests this:
				"For what you want, you should create an id field, map it to a long integer,
				and then copy your _id into that id field when you load the document. Then
				when you sort on the id field, you will get a numeric sort."
				
I can see from the results of

GET /gc/talk/_search
{
  "fields" : ["title", "author", "confid", "url"],
  "query" : {
    "match" : {
      "content" : "peace"
    }
  },
  "sort" : [ "_uid" ],
  "highlight" : {
    "fields" : {
      "content" : {"number_of_fragments": 50}
    }
  }
}

that _uid serves well for a lexographic sort on doc ID, but not a numeric one. "_id" doesn't sort at all.

Aug 25, 2015
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Why am I only getting 10 hits from JS when Sense is giving me 27 (for search term "peace")?

Ah, ES only returns the top 10 hits by default.
	http://stackoverflow.com/questions/8829468/elasticsearch-query-to-return-all-records
	https://www.elastic.co/guide/en/elasticsearch/guide/current/_search_lite.html
	https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-scroll.html#scroll-scan
	
How am I going to deal with that?
	It looks like I'm either going to have to query for a count and then query for all docs with size=count,
	or I'll have to query with scroll and paginate. (But I can't do scroll scan because scan prevents sorting...)
	
I think I'm going to fix the display of the empty table and then cook lunch. OK, that's done with ng-hide.


Aug 31, 2015
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

GET /gc/talk/_count
{
  "query" : {
    "match" : {
      "content" : "peace"
    }
  }
}

OK, I've figured out how to get all 27 results by querying for count and then querying for the entire body of results knowing the count. But, I still have major limitations:
	1- The JS script is now much less readable - how to compose it into smaller functions?
		* How to get the search to refrain from starting until the count is done?
	2- I need to implement an exclusively client-side (and therefore RESTful) pagination scheme.
		* I'm tempted to offer the user a chance to export to CSV so that he/she can them import to excel for additional searching/sorting.
	3- I still have the sorting done.